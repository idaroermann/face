{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial/handson session is designed based on the Visual Turing Test tutorial in here:\n",
    "https://github.com/mateuszmalinowski/visual_turing_test-tutorial\n",
    "Visual Turing Challenge\n",
    "Mateusz Malinowski and Mario Fritz\n",
    "Max-Plank Institute\n",
    "\n",
    "Mehdi Ghanimifard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "import numpy as np\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image as kimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Embedding, Concatenate, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loads my image_model \n",
    "pretrained_cnn_model = load_model('image_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can make this into a function (from file path to feature vectors)\n",
    "# this is function doesn't have an ideal performance but it would be useful for the sake of this tutorial (mehdi)\n",
    "\n",
    "def img2vec(image_path):\n",
    "    x = kimage.load_img(image_path, target_size=[48,48])#from 224,224\n",
    "    x_array = kimage.img_to_array(x)\n",
    "    xs_array = np.array([x_array,])\n",
    "    # notice that we are not using full capacity of the GPU when we are passing only one image per prediction.\n",
    "    # we could have a larger batch.\n",
    "    return pretrained_cnn_model.predict(preprocess_input(xs_array)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use image_model to extract features from .png format pictures: \n",
    "\n",
    "angry_images=[]\n",
    "happy_images=[]\n",
    "\n",
    "path = \"pngs/happy/output*.png\"\n",
    "for png in glob.glob(path):\n",
    "    happy_images.append(img2vec(png))\n",
    "print('Happy faces:   ', len(happy_images))   \n",
    "\n",
    "path = \"pngs/angry/output*.png\"\n",
    "for png in glob.glob(path):\n",
    "    angry_images.append(img2vec(png))\n",
    "print('Angry faces:   ', len(angry_images)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sentences (from prerocessing.py)\n",
    "happy_sents=np.load('happy_sents.npy')#With sentiment score above 0.6\n",
    "angry_sents=np.load('angry_sents.npy')#With sentiment score below 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splits each category and input in train and test before mapping. When mapping, one image is paired with some sentences, and we dont want to shuffle some anwers into the test set.\n",
    "train_angry_images=angry_images[:int(0.8*len(angry_images))]\n",
    "test_angry_images=angry_images[int(0.8*len(angry_images)):]\n",
    "\n",
    "train_happy_images=happy_images[:int(0.8*len(happy_images))]\n",
    "test_happy_images=happy_images[int(0.8*len(happy_images)):]\n",
    "\n",
    "train_angry_sents=angry_sents[:int(0.8*len(angry_sents))]\n",
    "test_angry_sents= [:int(0.8*len(angry_sents))]\n",
    "\n",
    "train_happy_sents=happy_sents[:int(0.8*len(happy_sents))]\n",
    "test_happy_sents= [:int(0.8*len(happy_sents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save(\"angry_images.npy\", angry_images)\n",
    "#np.save(\"happy_images.npy\", happy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#angry_images = [\n",
    "#    img2vec(\"pngs/angry/{0}.png\".format(image_name.strip()))\n",
    "#    for image_name in open('pngs/angry/{0}.png')\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code takes time:\n",
    "#X_images = [\n",
    "#    img2vec(\"data/daquar/images/{0}.png\".format(image_name.strip()))\n",
    "#    for image_name in open('data/daquar/qa.894.raw.train.format_triple.contexts')\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Maps each image with with the chosen sentences\n",
    "train=[]\n",
    "test=[]\n",
    "\n",
    "sent_count=0\n",
    "for image in train_angry_images:    \n",
    "    for step in range(6):\n",
    "        train.append((image, train_angry_sents[sent_count][0], 'NEG'))\n",
    "        sent_count=+1\n",
    "sent_count=0\n",
    "for image in train_happy_images:    \n",
    "    for step in range(6):\n",
    "        train.append((image, train_happy_sents[sent_count][0], 'POS'))\n",
    "        sent_count=+1\n",
    "        \n",
    "sent_count=0        \n",
    "for image in test_happy_images:\n",
    "    for step in range(5):\n",
    "        test.append((image, test_happy_sents[sent_count][0], 'POS'))\n",
    "        sent_count=+1 \n",
    "sent_count=0        \n",
    "\n",
    "for image in test_angry_images:\n",
    "    for step in range(5):\n",
    "        test.append((image, test_angry_sents[sent_count][0], 'NEG'))\n",
    "        sent_count=+1 \n",
    "    \n",
    "print('total pairs: ',len(train)+len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(train)\n",
    "shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('data points: ',len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#s=int((len(all_data)*0.8))#splits with 80% training, 20% test\n",
    "#train, test=all_data[:s], all_data[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=[(image,sent) for (image,sent,label) in train]\n",
    "ytrain=[label for (image,sent,label) in train]\n",
    "xtest=[(image,sent) for (image,sent,label) in test]\n",
    "ytest=[label for (image,sent,label) in test]\n",
    "\n",
    "image_size=len(train[0][0])\n",
    "sent_size=len(train[0][1])\n",
    "#labels=set(list(l for (i,s,l) in all_data))\n",
    "\n",
    "xtrain2 = list(zip(*xtrain))\n",
    "xtrain2 = [np.array(xtrain2[1]), np.array(xtrain2[0])]\n",
    "\n",
    "xtest2 = list(zip(*xtest))\n",
    "xtest2 = [np.array(xtest2[1]), np.array(xtest2[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(np.load('vocab.npy'))\n",
    "#image_size, sent_size = list(np.load('parameters.npy'))\n",
    "labels = {'POS', 'NEG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xtrain = [np.load('xtrain0.npy'), np.load('xtrain1.npy')]\n",
    "#ytrain = np.load('ytrain.npy')\n",
    "#xtest = [np.load('xtest0.npy'), np.load('xtest1.npy')]\n",
    "#ytest = np.load('ytest.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size=len(train[0][0])\n",
    "sent_size=len(train[0][1])\n",
    "#scores=list(l for (i,s,l) in all_data)\n",
    "\n",
    "xtrain2 = list(zip(*xtrain))\n",
    "xtrain2 = [np.array(xtrain2[1]), np.array(xtrain2[0])]#sentences, images\n",
    "\n",
    "xtest2 = list(zip(*xtest))\n",
    "xtest2 = [np.array(xtest2[1]), np.array(xtest2[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_question = Input([sent_size,])\n",
    "input_context = Input([image_size,])\n",
    "\n",
    "# learn embedings (size=50 as we chose just now :D)\n",
    "q_embs = Embedding(len(vocab), 50)(input_question)\n",
    "\n",
    "# encode the question\n",
    "q_encoded = LSTM(50)(q_embs)\n",
    "\n",
    "mlp_1 = Dense(image_size, activation='tanh')(q_encoded)\n",
    "\n",
    "q_composed = Concatenate()([input_context, mlp_1])\n",
    "\n",
    "mlp_2 = Dropout(0.2)(Dense(image_size, activation='relu')(q_composed))\n",
    "#mlp_2 = Dropout(0.2)(Dense(image_size, activation='relu')(mlp_1))\n",
    "\n",
    "final_a = Dense(len(labels), activation='softmax')(mlp_2)\n",
    "\n",
    "model = Model([input_question, input_context], final_a)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile('adam', 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(xtrain2, ytrain, epochs=100, batch_size=32, validation_split=0.1, callbacks=[EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('combi_model.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(xtest2, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict([xtest[0][:1], xtest[1][:1]])\n",
    "#print('answer predictions', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
