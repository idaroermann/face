{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sents 239232\n"
     ]
    }
   ],
   "source": [
    "d=open(\"dictionary.txt\", 'r', encoding='utf-8')\n",
    "s=open(\"sentiment_labels.txt\", encoding='utf-8')\n",
    "sents=[]\n",
    "labels=[]\n",
    "for line in d:\n",
    "    sents.append(line.split('|')[0])\n",
    "for line in s:\n",
    "    score=line.split('|')[1]\n",
    "    labels.append(score.split('\\n')[0])\n",
    "d.close()\n",
    "s.close()\n",
    "print('sents', len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_vector(size, sent_feat_temps):\n",
    "    return [0]*(size-len(sent_feat_temps)) + sent_feat_temps\n",
    "def create_vocab(fts_list):#takes a list of lists of words\n",
    "    rV=[]\n",
    "    for el in fts_list:\n",
    "        for word in el:\n",
    "            rV.extend(el)\n",
    "    rV=set(rV)\n",
    "    return ['<pad>'] + list(rV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language_data 150000\n",
      "padded_data 150000\n"
     ]
    }
   ],
   "source": [
    "token_sents=[]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for sent in sents:\n",
    "    sentence=word_tokenize(sent)\n",
    "    lem_sentence=[]\n",
    "    for word in sentence:\n",
    "        lem_sentence.append(lemmatizer.lemmatize(word.lower()))\n",
    "    token_sents.append(lem_sentence)\n",
    "\n",
    "#    print(sentence)\n",
    "#    input()\n",
    "zipped=list(zip(token_sents,labels))\n",
    "del zipped[0]#getting rid of the header\n",
    "zipped.sort(key = lambda x: len(x[0]), reverse=True)\n",
    "language_data=zipped[:150000]\n",
    "#list of tuples. One per sentence. ([list of lemmatized lowercase words in the sentence], a sentiment score)\n",
    "\n",
    "sentlist=[sent for sent,score in language_data]\n",
    "longest_sent = max(len(sent) for sent in sentlist)\n",
    "vocab=create_vocab(sentlist)\n",
    "vocabsize=len(vocab)\n",
    "inttofeat = dict(zip(range(vocabsize), vocab))\n",
    "feattoint = dict(zip(vocab, range(vocabsize)))\n",
    "\n",
    "print('language_data', len(language_data))\n",
    "\n",
    "padded_data=[]\n",
    "for sent,score in language_data:\n",
    "    feat=[feattoint[word] for word in sent]\n",
    "    padded_data.append((pad_vector(longest_sent, feat),score))\n",
    "\n",
    "print('padded_data', len(padded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative sentences:  54364\n",
      "positive sentences:  55674\n"
     ]
    }
   ],
   "source": [
    "#Now, sort the sentences in 3 categories:\n",
    "\n",
    "angry_sents=[]\n",
    "happy_sents=[]\n",
    "#neutral_sents=[]\n",
    "\n",
    "for sent,score in padded_data:\n",
    "    if 0.0 <= float(score) < 0.5:\n",
    "        angry_sents.append((sent,'NEG'))\n",
    "#    elif float(score) == 0.50:\n",
    "#        neutral_sents.append((sent,score))\n",
    "    elif 0.55 <= float(score) <= 1:\n",
    "        happy_sents.append((sent,'POS'))\n",
    "        \n",
    "print('negative sentences: ', len(angry_sents))\n",
    "print('positive sentences: ', len(happy_sents))\n",
    "#print('neutral', len(neutral_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"angry_sents.npy\", angry_sents)\n",
    "np.save(\"happy_sents.npy\", happy_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"fer2013/fer2013.csv\")#image data\n",
    "\n",
    "##0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "#angry_df=df[df.emotion == 0]\n",
    "#happy_df=df[df.emotion == 3]\n",
    "##neutral_df=df[df.emotion == 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save to folder as png-files\n",
    "#count=0\n",
    "#for row in angry_df.iterrows():\n",
    "#    image_feat=angry_df.iloc[count]['pixels'].split()\n",
    "#    image_feat = [int(i) for i in image_feat]\n",
    "#    new=np.array(image_feat).reshape((48,48)).astype(np.uint8)\n",
    "#    im = Image.fromarray(new)\n",
    "#    im.save('pngs/angry/output{}.png'.format(count))\n",
    "#    count=count+1\n",
    "    \n",
    "#count=0\n",
    "#for row in happy_df.iterrows():\n",
    "#    image_feat=happy_df.iloc[count]['pixels'].split()\n",
    "#    image_feat = [int(i) for i in image_feat]\n",
    "#    new=np.array(image_feat).reshape((48,48)).astype(np.uint8)\n",
    "#    im = Image.fromarray(new)\n",
    "#    im.save('pngs/happy/output{}.png'.format(count))\n",
    "#    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image as kimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you are running this for the first time in this machine, keras will download the pre-trained weights.\n",
    "pretrained_cnn_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def img2vec(image_path):\n",
    "    x = kimage.load_img(image_path, target_size=[224,224])\n",
    "    x_array = kimage.img_to_array(x)\n",
    "    xs_array = np.array([x_array,])\n",
    "    # notice that we are not using full capacity of the GPU when we are passing only one image per prediction.\n",
    "    # we could have a larger batch.\n",
    "    return pretrained_cnn_model.predict(preprocess_input(xs_array)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "angry_images=[]\n",
    "happy_images=[]\n",
    "\n",
    "path = \"pngs/happy/output*.png\"\n",
    "for png in glob.glob(path):\n",
    "    happy_images.append(img2vec(png))\n",
    "    \n",
    "path = \"pngs/angry/output*.png\"\n",
    "for png in glob.glob(path):\n",
    "    angry_images.append(img2vec(png))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry images:  4953\n",
      "happy images:  8989\n"
     ]
    }
   ],
   "source": [
    "print('angry images: ', len(angry_images))\n",
    "print('happy images: ', len(happy_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"angry_images.npy\", angry_images)\n",
    "np.save(\"happy_images.npy\", happy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pairs:  74663\n"
     ]
    }
   ],
   "source": [
    "all_data=[]\n",
    "\n",
    "sent_count=0\n",
    "for image in angry_images:\n",
    "    \n",
    "    for step in range(6):\n",
    "        all_data.append((image, angry_sents[sent_count][0], 'NEG'))\n",
    "        sent_count=+1\n",
    "        \n",
    "sent_count=0        \n",
    "for image in happy_images:\n",
    "    for step in range(5):\n",
    "        all_data.append((image, happy_sents[sent_count][0], 'POS'))\n",
    "        sent_count=+1            \n",
    "    \n",
    "#for sent,score in angry_sents:\n",
    "#    for step in range(len(angry_sents)-1):\n",
    "#        image_feat=angry_df.iloc[step]['pixels'].split()\n",
    "#        image_feat = [int(i) for i in image_feat]\n",
    "#        all_data.append((np.array(image_feat),sent,'NEG'))\n",
    "                    \n",
    "#for sent,score in happy_sents:#[:7500]:\n",
    "#    image_feat=happy_df.iloc[randint(0, len(happy_df)-1)]['pixels'].split()\n",
    "#    image_feat = [int(i) for i in image_feat]\n",
    "#    all_data.append((np.array(image_feat),sent,'POS'))\n",
    "\n",
    "#for sent,score in neutral_sents:\n",
    "#    image_feat=neutral_df.iloc[randint(0, len(neutral_df)-1)]['pixels'].split()\n",
    "#    image_feat = [int(i) for i in image_feat]\n",
    "#    all_data.append((np.array(image_feat),sent,'NEU'))\n",
    "print('total pairs: ',len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=int((len(all_data)*0.8))#splits with 80% training, 20% test\n",
    "train, test=all_data[:s], all_data[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=[(image,sent) for (image,sent,label) in train]\n",
    "ytrain=[label for (image,sent,label) in train]\n",
    "xtest=[(image,sent) for (image,sent,label) in test]\n",
    "ytest=[label for (image,sent,label) in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size=len(all_data[0][0])\n",
    "sent_size=len(all_data[0][1])\n",
    "labels=set(list(l for (i,s,l) in all_data))\n",
    "\n",
    "xtrain2 = list(zip(*xtrain))\n",
    "xtrain2 = [np.array(xtrain2[1]), np.array(xtrain2[0])]\n",
    "\n",
    "xtest2 = list(zip(*xtest))\n",
    "xtest2 = [np.array(xtest2[1]), np.array(xtest2[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_codes = {\n",
    "    'POS': 0,\n",
    "    'NEU': 1,\n",
    "    'NEG': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain2 = np.array([cat_codes[c] for c in ytrain])\n",
    "ytest2 = np.array([cat_codes[c] for c in ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('parameters.npy',[image_size, sent_size]) \n",
    "np.save(\"vocab.npy\", vocab)\n",
    "np.save(\"xtrain0.npy\", xtrain2[0])\n",
    "np.save(\"xtrain1.npy\", xtrain2[1])\n",
    "np.save(\"ytrain.npy\", ytrain2)\n",
    "np.save(\"xtest0.npy\", xtest2[0])\n",
    "np.save(\"xtest1.npy\", xtest2[1])\n",
    "np.save(\"ytest.npy\", ytest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
